{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Group 4 -- ECG Data\n",
        "Lara de Bats (5022037), Josefien van den Berg (4663381), Merel Goossens (4856902), Amber Liqui Lung (4464168)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment we wil test certain classifiers in order to create a classifier model to distinguish between normal and abnormal ECG's. The code is divided in different segments that are explained in our report."
      ],
      "metadata": {
        "id": "u0jPpiE5pyEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading packages\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import numpy as np\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import set_config\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from IPython.display import display\n",
        "\n",
        "pd.set_option('display.max_rows', 5)"
      ],
      "metadata": {
        "id": "f-5Aw7sQpsDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EG78VSHfhNi"
      },
      "source": [
        "## 1. Data loading and initial split\n",
        "\n",
        "Below we load the ECG data, convert it to a dataframe an clean the data.First we are going to start with loading the CS file into a dataframe. Then we are going to split the dataset into test data and training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiDn2Sk-VWqE",
        "outputId": "9da6d861-d5ec-4d60-947a-9cc6402b6ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TM10007_ML_ECG_group4' already exists and is not an empty directory.\n",
            "The number of samples: 827\n",
            "The number of columns: 9001\n"
          ]
        }
      ],
      "source": [
        "# Load CSV file into dataframe\n",
        "!git clone https://github.com/JosefienBerg/TM10007_ML_ECG_group4.git\n",
        "\n",
        "with zipfile.ZipFile('/content/TM10007_ML_ECG_group4/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/TM10007_ML_ECG_group4/ecg')\n",
        "\n",
        "df = pd.read_csv('/content/TM10007_ML_ECG_group4/ecg/ecg_data.csv', index_col=0)\n",
        "\n",
        "print(f'The number of samples: {len(df.index)}')\n",
        "print(f'The number of columns: {len(df.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We explore our dataset to see how many patients we have with label 1 and how many with lable 0.\n"
      ],
      "metadata": {
        "id": "OaN6z_VynlYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many patients have a normal or abnormal ECG?\n",
        "count0= (df['label'] == 0).sum()\n",
        "count1= (df['label'] == 1).sum()\n",
        "print(f'There are {count0} patients with label 0')\n",
        "print(f'There are {count1} patients with label 1')\n",
        "# Since the majority of patients has no abnormalities we can conclude that label 0 is normal and label 1 is abnormal"
      ],
      "metadata": {
        "id": "6uzs9dYjnrHt",
        "outputId": "c8b0d75f-5e32-4c62-ceaa-a2dd509735c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 681 patients with label 0\n",
            "There are 146 patients with label 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will perform our initial split"
      ],
      "metadata": {
        "id": "ORtoTNM7LF54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the whole data set in a training and test set\n",
        "features = df.loc[:, df.columns !=\"label\"].to_numpy()\n",
        "labels = df[\"label\"].to_numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split (features, labels, train_size = 0.8, random_state = 42) \n",
        "print(f\"The training set has {x_train.shape[0]} samples and {x_train.shape[1]} features with {y_train.shape[0]} labels\")\n",
        "print(f\"The test has {x_test.shape[0]} samples and {x_test.shape[1]} features with {y_test.shape[0]} labels\")"
      ],
      "metadata": {
        "id": "7WHZbHF0LKCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Imputation"
      ],
      "metadata": {
        "id": "hbyr7EH1fUE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# block 1"
      ],
      "metadata": {
        "id": "nIf-5Y4zm3ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# block 2"
      ],
      "metadata": {
        "id": "zb3vR84XLPsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data scaling, extraction and feature selection\n",
        "In this section we will explore multiple scaling methods, determine if we will use PCA and define the treshold and we will explore mutliple feature selection methods. After this section we will have a dictionary containing the x_train data for all combinations of the chosen scaling, extraction (PCA) and selection methods."
      ],
      "metadata": {
        "id": "WIucopYVnYBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are multiple ways to scale features by standarization and normalization."
      ],
      "metadata": {
        "id": "qYnQ0Ml9oA1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Standardization of the data\n",
        "scaler_standard = StandardScaler()\n",
        "x_scaled_standard = scaler_standard.fit_transform(x_train) \n",
        "\n",
        "# 1. Min-max scaling\n",
        "scaler_minmax = MinMaxScaler()\n",
        "x_scaled_minmax = scaler_minmax.fit_transform(x_train)\n",
        "\n",
        "# # 2. Robust scaling --> Robust is removed due to a to extensive loading time during the training of SVC\n",
        "# scaler_robust= RobustScaler()\n",
        "# x_scaled_robust = scaler_robust.fit_transform(x_train)\n",
        "\n",
        "x_scaled = {\"standard\":x_scaled_standard, \"minmax\":x_scaled_minmax}"
      ],
      "metadata": {
        "id": "7lPiglbIne_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to perform PCA and determine the treshold."
      ],
      "metadata": {
        "id": "J9t4kREtoB0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "plt.close('all') #before plotting, close all old windows\n",
        "x_scaled_pca = {} #create dictionary to add all combinations of scaling combined with PCA to\n",
        "\n",
        "for key, x in x_scaled.items():\n",
        "    \n",
        "    # applying pca\n",
        "    pca_setting = PCA(n_components = 0.95) # threshold at 95% method\n",
        "    x_pca = pca_setting.fit_transform(x)\n",
        "    x_scaled_pca[f\"x_{key}_PCA\"] = x_pca\n",
        "\n",
        "    print(x_pca.shape)\n",
        "\n",
        "    # plot to show treshold choice\n",
        "    pca_figure = PCA().fit(x)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    xi = np.arange(1, 662, step=1)\n",
        "    y = np.cumsum(pca_figure.explained_variance_ratio_)\n",
        "\n",
        "    plt.ylim(0.0,1.1)\n",
        "    plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
        "\n",
        "    plt.xlabel('Number of Components')\n",
        "    plt.xticks(np.arange(0, 661, step=50)) #change from 0-based array index to 1-based human-readable label\n",
        "    plt.ylabel('Cumulative variance (%)')\n",
        "    plt.title(f'The number of components needed to explain variance for scaling method {key}')\n",
        "\n",
        "    plt.axhline(y=0.95, color='r', linestyle='-')\n",
        "    plt.text(0.5, 0.9, '95% cut-off threshold', color = 'red', fontsize=16)\n",
        "\n",
        "    plt.axhline(y=0.85, color='r', linestyle='-')\n",
        "    plt.text(0.5, 0.8, '85% cut-off threshold', color = 'red', fontsize=16)\n",
        "\n",
        "    plt.axhline(y=0.75, color='r', linestyle='-')\n",
        "    plt.text(0.5, 0.7, '75% cut-off threshold', color = 'red', fontsize=16)\n",
        "\n",
        "    ax.grid(axis='x')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "nVCz7FgOnglf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasty we will look at feature selection. "
      ],
      "metadata": {
        "id": "4Cnit418Lpz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection with and without PCA\n",
        "x_scaled_selected = {} #create dictionary to add all combinations of scaling with or without PCA combined with feature selection\n",
        "\n",
        "selector = SelectKBest(f_classif)\n",
        "k = 50\n",
        "\n",
        "#Including PCA\n",
        "for key, x in x_scaled_pca.items():\n",
        "    selector.k = k\n",
        "    x_train_ffs = selector.fit_transform(x_train, y_train)  # ffs = f-test feature selection\n",
        "x_scaled_selected[f\"{key}_ffs\"] =  x_train_ffs\n",
        "\n",
        "#Exclusing PCA\n",
        "for key, x in x_scaled.items():\n",
        "    selector.k = k\n",
        "    x_train_ffs = selector.fit_transform(x_train, y_train)  # ffs = f-test feature selection\n",
        "x_scaled_selected[f\"x_{key}_ffs\"] =  x_train_ffs"
      ],
      "metadata": {
        "id": "JcMcEILqLpeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we finish with a dictionary x_scaled_selected that inclused all combinations between feature scaling, feature extraction (PCA) and feature selection."
      ],
      "metadata": {
        "id": "mXpSLiVhLy0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Classifiers: hyperparameter tuning and fitting\n",
        "In this section we will build a neural network and train our different clasiffiers (standard and the neural network) and compare their functionality in terms of F1 and average precision. We will perform this for all possible combinations of scaling, selection and classification possibilities. This is also the section were we will tune our parameters."
      ],
      "metadata": {
        "id": "UXm9Ps4sm-v-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we are going to set the models and parameters we are going to tune and write the function for tuning. "
      ],
      "metadata": {
        "id": "jWntzXM0oGlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating a dictionary of all proposed classifiers\n",
        "models = {\"GaussianNB\": GaussianNB(),\n",
        "          \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
        "          \"RandomForestClassifier\":RandomForestClassifier(),\n",
        "          \"SVC\":SVC()\n",
        "          }\n",
        "\n",
        "# Creating a dictionary of all models with default paramters (note; random state=42 only added in the last run)\n",
        "model_parameters = {\"GaussianNB\": {}, #no parameters to be set\n",
        "                    \"KNeighborsClassifier\":{\"n_neighbors\":[x for x in range(20, 300)], \"weights\": [\"distance\", \"uniform\"]},\n",
        "                    \"RandomForestClassifier\":{\"n_estimators\":[x for x in range(5,10)], \"max_depth\":[x for x in range (1,20)], \"min_samples_leaf\": [x for x in range (1, 20)]},\n",
        "                    \"SVC\":{\"C\": np.logspace(-2, 5, num=10), \"kernel\": [\"linear\", \"rbf\", \"poly\"], \"degree\":[x for x in range (2,4)]}\n",
        "                    }\n",
        "\n",
        "# Function to clean up results and create dataframe with wanted results\n",
        "def get_dataframe_from_results(results, scoring):\n",
        "  \"\"\" This function makes sure that we can clean up the results that we get from the grid search and leaves is with the necessary results\"\"\"\n",
        "  df_to_concat = [pd.DataFrame(results[\"params\"])]\n",
        "\n",
        "  for key in scoring:\n",
        "    df_to_concat.append(pd.DataFrame(results[f\"mean_test_{key}\"], columns=[key]))\n",
        "\n",
        "  return pd.concat(df_to_concat, axis=1)\n",
        "\n",
        "# Function to do a grid search on each model using the parameters in the model_parameter dictionary\n",
        "def parametertuning(Models, ModelParameters, n_splits, random_state, scoring, refit, X, Y):\n",
        "  \"\"\" This function performs the parameter tuning by doing a gridsearch with multiple parameters per model it returns the results that are cleaned up and only show the necessary\"\"\"\n",
        "  results = {} #create a dictionary to save results\n",
        "\n",
        "  for model_name, parameters in ModelParameters.items():\n",
        "    print(f\"Grid searching {model_name}\")\n",
        "    model = Models[model_name]  # Find corresponding model in models dict\n",
        "\n",
        "    # Create the Cross vallidation object\n",
        "    cv = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)  \n",
        "    \n",
        "    # Perform a grid search for the best parameters for the model using the test data and KFold\n",
        "    grid_search = GridSearchCV(model, parameters, cv=cv, n_jobs=-1, verbose=False, scoring=scoring, refit=refit).fit(X, Y) \n",
        "    \n",
        "    # Results of grid search\n",
        "    best_estimator = grid_search.best_estimator_ # Returns the model with the best parameters filled in based on refit scoring metric\n",
        "    grid_search_results = get_dataframe_from_results(grid_search.cv_results_, scoring) # Extracts the necessary results \n",
        "\n",
        "    # Add the results to the dictionary\n",
        "    results[model_name] = {\"BestEstimator\": best_estimator, \"GSresults\": grid_search_results}\n",
        " \n",
        "  return results"
      ],
      "metadata": {
        "id": "rB8WQrT8nBlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going write the function to plot the relation between the scoring type and certain parameters in order to prove that we chose the right parameter combinations."
      ],
      "metadata": {
        "id": "7Fo3B9GtoHfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we do not tune any paramters in GaussianNB we don't need to make a plot\n",
        "\n",
        "#---------------Plot for KNeighborsClassifier---------------\n",
        "def plot_knn(results, scoring, combination_name):\n",
        "  knn_df = results[\"KNeighborsClassifier\"][\"GSresults\"]\n",
        "  uni_knn_df = knn_df[knn_df[\"weights\"] == \"uniform\"]\n",
        "  dist_knn_df = knn_df[knn_df[\"weights\"] == \"distance\"]\n",
        "\n",
        "  for key in scoring:\n",
        "    index_maxscore = knn_df[key].idxmax()\n",
        "\n",
        "    # pl.figure(f\"KNeighborsClassifier, {combination_name}, {key}\")\n",
        "    plt.plot(uni_knn_df[\"n_neighbors\"].to_numpy(), uni_knn_df[key].to_numpy(), label= \"uniform\")\n",
        "    plt.plot(dist_knn_df[\"n_neighbors\"].to_numpy(), dist_knn_df[key].to_numpy(), label= \"distance\")\n",
        "    plt.scatter(knn_df[\"n_neighbors\"][index_maxscore], knn_df[key].max(), s= 200, marker = \"*\", c=\"m\")\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title(f\"The relation between the {key} of the KNN classifier and the parameters {combination_name}\")\n",
        "    plt.xlabel(\"N-neighbour\")\n",
        "    plt.ylabel(f\"{key}\")\n",
        "    plt.show()\n",
        "\n",
        "#---------------Plot for SVC Classifier--------------- \n",
        "def plot_svc(results, scoring, combination_name):\n",
        "  svc_df = results[\"SVC\"][\"GSresults\"]\n",
        "  linear_svc_df = svc_df[svc_df[\"kernel\"]==\"linear\"]\n",
        "  rbf_svc_df = svc_df[svc_df[\"kernel\"]==\"rbf\"]\n",
        "  poly_svc_df = svc_df[svc_df[\"kernel\"]==\"poly\"]\n",
        "\n",
        "  for key in scoring:\n",
        "    index_maxscore = svc_df[key].idxmax()\n",
        "\n",
        "    # pl.figure(f\"SVC Classifier, {combination_name}, {key}\")\n",
        "    for i in range(2,5):\n",
        "      degree_svc_df = poly_svc_df[poly_svc_df[\"degree\"]==i]\n",
        "      plt.plot(degree_svc_df[\"C\"].to_numpy(), degree_svc_df[key].to_numpy(), label= f\"poly degree {i}\")\n",
        "\n",
        "    plt.plot(linear_svc_df[\"C\"].to_numpy(), linear_svc_df[key].to_numpy(), label= \"linear\")\n",
        "    plt.plot(rbf_svc_df[\"C\"].to_numpy(), rbf_svc_df[key].to_numpy(), label= \"rbf\")\n",
        "    plt.scatter(svc_df[\"C\"][index_maxscore], svc_df[key].max(), s = 200, marker = \"*\", c=\"m\")\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title(f\"The relation between the {key} of the SVC classifier and the parameters {combination_name}\")\n",
        "    plt.xscale(\"log\")\n",
        "    plt.xlabel(\"C-value\")\n",
        "    plt.ylabel(f\"{key}\")\n",
        "    plt.show()\n",
        "\n",
        "# ---------------Plots for RandomForestClassifier---------------\n",
        "def plot_randomforest(results, scoring, combination_name):\n",
        "  forest_df = results[\"RandomForestClassifier\"][\"GSresults\"]\n",
        "\n",
        "  for key in scoring:\n",
        "    index_maxscore = forest_df[key].idxmax() #index (number of the row)\n",
        "\n",
        "    fig = px.scatter_3d(forest_df, x=\"max_depth\", y=\"min_samples_leaf\", z=\"n_estimators\", color=key,  title=f\"The relation between the {key} of the Random Forest and the parameters {combination_name}\")\n",
        "    fig.add_traces(px.scatter_3d(forest_df.sample[key].loc[index_maxscore], x=\"max_depth\", y=\"min_samples_leaf\", z=\"n_estimators\").update_traces(marker_size=20, marker_color=\"yellow\").data)\n",
        "  \n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "YS-1NeZunEfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beneath, we write the function to display the best scoring results for each model."
      ],
      "metadata": {
        "id": "DjUe1_wAoJpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot tabel with scoring metric and optimal paramater combination per scalor and selection\n",
        "def create_table_of_results(results_all_combinations, combination_name):\n",
        "  F1_scores = []\n",
        "  Average_Precision_scores = []\n",
        "  model_names = [] \n",
        "\n",
        "  results = results_all_combinations[combination_name]\n",
        "\n",
        "  for model_name in results:\n",
        "    F1 = results[model_name][\"GSresults\"][\"F1\"].max()\n",
        "    Average_Precision = results[model_name][\"GSresults\"][\"Average Precision\"].max()\n",
        "    F1_scores.append(F1)\n",
        "    Average_Precision_scores.append(Average_Precision)\n",
        "    model_names.append(model_name)\n",
        "\n",
        "  print(f\"Table of results for combination {combination_name}\")\n",
        "  display(pd.DataFrame({\"ModelName\":model_names, \"F1\":F1_scores, \"Average Precision\":Average_Precision_scores}).style.hide(axis='index'))\n",
        "  print()"
      ],
      "metadata": {
        "id": "a3_dsVkEoKto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we will call all functions written to tune all the parameters and plot the results for each combination of scaling, PCA and selection."
      ],
      "metadata": {
        "id": "IA5YZ10iM5OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform training\n",
        "results_all_combinations = {}\n",
        "for combination_name, data in x_scaled_selected.items():\n",
        "  print(combination_name)\n",
        "  \n",
        "  # Perform grid search\n",
        "  scoring = {\"F1\":\"f1\", \"Average Precision\":\"average_precision\"} #Determine what type of scoring you want to use\n",
        "  results = parametertuning(models, model_parameters, 5, None, scoring, \"Average Precision\", data, y_train)\n",
        "  results_all_combinations[combination_name] = results"
      ],
      "metadata": {
        "id": "isqnuYlhM6Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create visualization of results \n",
        "plt.close('all') #make sure you class all windows before plotting to prevent plotting in the same figure\n",
        "\n",
        "for combination_name, data in x_scaled_pca.items():\n",
        "\n",
        "  #Create all plots to show the relation between the scoring type and parameters for every combination\n",
        "  plot_knn(results_all_combinations[combination_name], scoring, combination_name)\n",
        "  plot_svc(results_all_combinations[combination_name], scoring, combination_name)\n",
        "  plot_randomforest(results_all_combinations[combination_name], scoring, combination_name)"
      ],
      "metadata": {
        "id": "srThEOW1NPv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create table with results for every combination\n",
        "for combination_name, data in x_scaled_pca.items():\n",
        "  create_table_of_results(results_all_combinations, combination_name)"
      ],
      "metadata": {
        "id": "S3yr30PFNSgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. The final model\n",
        "After the previous steps we determined the best combination of scaling, PCA, feature selection and classification for our final model. Underneath we wrote the final pipeline that returns the mean accuracy of the model on the test data."
      ],
      "metadata": {
        "id": "sqnvS2MX2ozi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Write final pipeline with chosen combinations\n",
        "# def final_pipeline(x_train, y_train, x_test, y_test):\n",
        "\n",
        "#   # Determine steps of the pipeline\n",
        "#   pipe = Pipeline([('scaler', MinMaxScaler()), ('pca', PCA(n_components = 0.95)), ('svc', SVC(C=1, kernel= \"rbf\"))])\n",
        "\n",
        "#   # Visualize the pipeline\n",
        "#   set_config(display = \"diagram\")\n",
        "#   pipe\n",
        "\n",
        "#   # Fit the pipeline on the training data \n",
        "#   pipe.fit(x_train, y_train)\n",
        "\n",
        "#   # Compute the mean accuracy of the model on the test data\n",
        "#   score = pipe.score(x_test, y_test) #Returns the mean accuracy of the model on test data\n",
        "#   return score\n",
        "\n",
        "# #Execute pipeline to get the mean accuracy of the final model on the test data\n",
        "# accuracy = final_pipeline(x_train, y_train, x_test, y_test)\n",
        "# print(f\"The accuracy of the final model on the test data is {accuracy}\")\n"
      ],
      "metadata": {
        "id": "QAaZY7vY2vJg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}